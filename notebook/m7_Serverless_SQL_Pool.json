{
	"name": "m7_Serverless_SQL_Pool",
	"properties": {
		"folder": {
			"name": "m7"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"runAsWorkspaceSystemIdentity": false,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "a8126c74-3985-47f0-96c2-5e716f630b02"
			}
		},
		"metadata": {
			"saveOutput": true,
			"synapse_widget": {
				"version": "0.1"
			},
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## What this notebook does\r\n",
					"\r\n",
					"Cell one: gets File, paths from ingestion, path to save + loads as df in spark\r\n",
					"\r\n",
					"Cell two: data transformation of the data cell further\r\n",
					""
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"tags": [
						"parameters"
					]
				},
				"source": [
					"notebook = \"fromNotebook\"\r\n",
					"\r\n",
					""
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "python"
					},
					"collapsed": false,
					"tags": []
				},
				"source": [
					"%%pyspark\r\n",
					"\r\n",
					"# default table of taking the new dataset\r\n",
					"FILE = 'part-00000-ea840941-f8fb-4340-b02a-d746e2c80fbc-c000.snappy.parquet'\r\n",
					"PATH = f'abfss://scratch@traininglakehouse103.dfs.core.windows.net/m6_output/'\r\n",
					"\r\n",
					"# Loading the data and using the display/limit function to show first 10 rows. \r\n",
					"df = spark.read.load(f'{PATH}{FILE}', format='parquet')\r\n",
					"display(df.limit(10))"
				],
				"execution_count": 2
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Notice there are 'duplicate values' "
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": true
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false,
					"tags": []
				},
				"source": [
					"import pyspark.sql.functions as F\r\n",
					"\r\n",
					"df_agg = (\r\n",
					"    df\r\n",
					"    .drop(F.col('storeFwdFlag'))\r\n",
					"    .groupBy(['hack_license','medallion','pickup_datetime','dropoff_longitude','dropoff_latitude'])\r\n",
					"    .agg(\r\n",
					"        F.round(F.sum('fare_amount'),2).alias('fareAmountTotal'),\r\n",
					"        F.sum('surcharge').alias('surchageTotal'),\r\n",
					"        F.round(F.mean('mta_tax'),2).alias('taxTotal'),\r\n",
					"        F.round(F.mean('tip_amount'),2).alias('tipAmountAverage'),\r\n",
					"        F.round(F.sum('total_amount'),2).alias('totalAmount')\r\n",
					"    )\r\n",
					"\r\n",
					")\r\n",
					"\r\n",
					""
				],
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"print(f'rows from initial dataset: {df.count()}\\n rows from transformation dataset: {df_agg.count()}')\r\n",
					"\r\n",
					"\r\n",
					"df_agg.show()"
				],
				"execution_count": 4
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## INTO Serverless SQL POOL \r\n",
					"\r\n",
					"spark.sql(\"CREATE DATABASE IF NOT EXISTS m7\")\r\n",
					"\r\n",
					"(\r\n",
					"    df_agg\r\n",
					"    .write\r\n",
					"    .mode(\"overwrite\")\r\n",
					"    .saveAsTable(f\"TaxiDemoAggregated_{notebook}\")\r\n",
					")\r\n",
					""
				],
				"execution_count": 5
			}
		]
	}
}